{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "\n",
    "    sigmoid = 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    return sigmoid\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \n",
    "    sigmoid_derivative = sigmoid(x) * (1-sigmoid(x))\n",
    "    \n",
    "    return sigmoid_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(\n",
    "            self,\n",
    "            X_data,\n",
    "            Y_data,\n",
    "            n_hidden_neurons,\n",
    "            n_categories,\n",
    "            epochs,\n",
    "            batch_size,\n",
    "            eta,\n",
    "            lmbd):\n",
    "\n",
    "        self.X_data_full = X_data\n",
    "        self.Y_data_full = Y_data\n",
    "\n",
    "        self.n_inputs = X_data.shape[0]\n",
    "        self.n_features = X_data.shape[1]\n",
    "        self.n_hidden_neurons = n_hidden_neurons\n",
    "        self.n_categories = n_categories\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.iterations = self.n_inputs // self.batch_size\n",
    "        self.eta = eta\n",
    "        self.lmbd = lmbd\n",
    "\n",
    "        self.create_biases_and_weights()\n",
    "\n",
    "    def create_biases_and_weights(self):\n",
    "        self.hidden_weights = np.random.randn(self.n_features, self.n_hidden_neurons)\n",
    "        self.hidden_bias = np.zeros(self.n_hidden_neurons) + 0.01\n",
    "\n",
    "        self.output_weights = np.random.randn(self.n_hidden_neurons, self.n_categories)\n",
    "        self.output_bias = np.zeros(self.n_categories) + 0.01\n",
    "\n",
    "    def feed_forward(self):\n",
    "        # feed-forward for training\n",
    "        self.z_h = np.matmul(self.X_data, self.hidden_weights) + self.hidden_bias\n",
    "        self.a_h = sigmoid(self.z_h)\n",
    "\n",
    "        self.z_o = np.matmul(self.a_h, self.output_weights) + self.output_bias\n",
    "        self.a_o = sigmoid(self.z_o)\n",
    "        #exp_term = np.exp(self.z_o)\n",
    "        #print('exp_term SUM', np.sum(exp_term, keepdims=True))\n",
    "        #self.probabilities = exp_term / np.sum(exp_term, keepdims=True)#, axis=1, keepdims=True)\n",
    "        #print(self.probabilities)\n",
    "\n",
    "    def feed_forward_out(self, X):\n",
    "        # feed-forward for output\n",
    "        z_h = np.matmul(X, self.hidden_weights) + self.hidden_bias\n",
    "        a_h = sigmoid(z_h)\n",
    "\n",
    "        z_o = np.matmul(a_h, self.output_weights) + self.output_bias\n",
    "        a_o = sigmoid(z_o)\n",
    "        #exp_term = np.exp(z_o)\n",
    "        #probabilities = exp_term / np.sum(exp_term, keepdims=True)#, axis=1, keepdims=True)\n",
    "        #return probabilities\n",
    "        return a_o\n",
    "\n",
    "    def backpropagation(self):\n",
    "        #error_output = self.probabilities - self.Y_data\n",
    "        error_output = self.a_o - self.Y_data\n",
    "        error_hidden = np.matmul(error_output, self.output_weights.T) * self.a_h * (1 - self.a_h)\n",
    "\n",
    "        self.output_weights_gradient = np.matmul(self.a_h.T, error_output)\n",
    "        self.output_bias_gradient = np.sum(error_output, axis=0)\n",
    "\n",
    "        self.hidden_weights_gradient = np.matmul(self.X_data.T, error_hidden)\n",
    "        self.hidden_bias_gradient = np.sum(error_hidden, axis=0)\n",
    "\n",
    "        if self.lmbd > 0.0:\n",
    "            self.output_weights_gradient += self.lmbd * self.output_weights\n",
    "            self.hidden_weights_gradient += self.lmbd * self.hidden_weights\n",
    "\n",
    "        self.output_weights -= self.eta * self.output_weights_gradient\n",
    "        self.output_bias -= self.eta * self.output_bias_gradient\n",
    "        self.hidden_weights -= self.eta * self.hidden_weights_gradient\n",
    "        self.hidden_bias -= self.eta * self.hidden_bias_gradient\n",
    "        \n",
    "        #print('here, have updated by', self.eta * self.output_weights_gradient)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.feed_forward_out(X)\n",
    "        #print(probabilities)\n",
    "        #return np.argmax(probabilities, axis=1)\n",
    "        return(probabilities)\n",
    "        \n",
    "    def predict_probabilities(self, X):\n",
    "        probabilities = self.feed_forward_out(X)\n",
    "        return probabilities\n",
    "\n",
    "    def train(self):\n",
    "        data_indices = np.arange(self.n_inputs)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(self.iterations):\n",
    "                # pick datapoints with replacement\n",
    "                chosen_datapoints = np.random.choice(\n",
    "                    data_indices, size=self.batch_size, replace=True\n",
    "                )\n",
    "\n",
    "                # minibatch training data\n",
    "                self.X_data = self.X_data_full[chosen_datapoints]\n",
    "                self.Y_data = self.Y_data_full[chosen_datapoints]\n",
    "                \n",
    "                self.feed_forward()\n",
    "                self.backpropagation()\n",
    "                \n",
    "                \n",
    "    def printing(self):\n",
    "        #print('prob', self.probabilities)\n",
    "        print('O_w',  self.output_weights)\n",
    "        print('O_b',  self.output_bias)\n",
    "        print('H_w',  self.hidden_weights)\n",
    "        print('H_B',  self.hidden_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanDict = {}\n",
    "df = pd.read_excel('creditcard_data.xls', header=1, skiprows=0, index_col=0, na_values=nanDict)\n",
    "df.rename(index=str, columns={\"default payment next month\": \"defaultPaymentNextMonth\"}, inplace=True)# Features and targets \n",
    "\n",
    "df = df.drop(df[(df.BILL_AMT1 == 0) &\n",
    "                (df.BILL_AMT2 == 0) &\n",
    "                (df.BILL_AMT3 == 0) &\n",
    "                (df.BILL_AMT4 == 0) &\n",
    "                (df.BILL_AMT5 == 0) &\n",
    "                (df.BILL_AMT6 == 0)].index)\n",
    "\n",
    "df = df.drop(df[(df.PAY_AMT1 == 0) &\n",
    "                (df.PAY_AMT2 == 0) &\n",
    "                (df.PAY_AMT3 == 0) &\n",
    "                (df.PAY_AMT4 == 0) &\n",
    "                (df.PAY_AMT5 == 0) &\n",
    "                (df.PAY_AMT6 == 0)].index)\n",
    "\n",
    "X = df.loc[:, df.columns != 'defaultPaymentNextMonth'].values\n",
    "y = df.loc[:, df.columns == 'defaultPaymentNextMonth'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "onehotencoder = OneHotEncoder(categories = \"auto\")\n",
    "\n",
    "X = ColumnTransformer(\n",
    "    [(\"\", onehotencoder,  [1, 2, 3, 4]),],\n",
    "    remainder=\"passthrough\"\n",
    ").fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.5, test_size = 1-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# One-hot's of the target vector\n",
    "y_train_onehot, y_test_onehot = onehotencoder.fit_transform(y_train), onehotencoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_try = np.zeros(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "n_inputs, n_features = X_train.shape\n",
    "n_hidden_neurons = 50\n",
    "n_categories = 1\n",
    "epochs = 10\n",
    "batch_size = 80\n",
    "#iterations = n_inputs // batch_size\n",
    "iterations = 10\n",
    "eta = 0.001\n",
    "lmbd = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = NeuralNetwork(X_train.toarray(), y_train, eta=eta, lmbd=lmbd, epochs=epochs, batch_size=batch_size,\n",
    "                    n_hidden_neurons=n_hidden_neurons, n_categories=n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.train()\n",
    "test_predict = dnn.predict(X_test.toarray())\n",
    "test_predict[test_predict >= 0.5] = 1\n",
    "test_predict[test_predict < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dnn.printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test set:  0.7992841602919503\n",
      "0.2770475227502528\n",
      "[[10841   374]\n",
      " [ 2486   548]]\n"
     ]
    }
   ],
   "source": [
    "# accuracy score from scikit library\n",
    "print(\"Accuracy score on test set: \", accuracy_score(y_test, test_predict))\n",
    "print(f1_score(y_test, test_predict))\n",
    "print(confusion_matrix(y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992841602919503\n",
      "0.4802154547337892\n",
      "[[10581  1875]\n",
      " [  634  1159]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,1), alpha=0.1, batch_size=80, learning_rate = 'constant', learning_rate_init = 10e-4, max_iter=100, activation='logistic')\n",
    "mlp.fit(X_train.toarray(), np.ravel(y_train))\n",
    "#print(mlp.score(X_test, y_test)\n",
    "\n",
    "y_pred = mlp.predict(X_test.toarray())\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_pred, np.ravel(y_test)))\n",
    "print(confusion_matrix(y_pred, np.ravel(y_test)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
